{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries and Set Mixed Precision Policy",
   "id": "7c4b4472f802c753"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T17:54:12.062140Z",
     "start_time": "2024-08-10T17:53:59.543294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from datasets import Dataset, load_from_disk, concatenate_datasets\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "\n",
    "# Set mixed precision policy\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n"
   ],
   "id": "f4d6abb6751e5cc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU, compute capability 8.6\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\mixed_precision\\loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set TensorFlow GPU Configuration",
   "id": "666bce6a4e6aff24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T17:54:12.077298Z",
     "start_time": "2024-08-10T17:54:12.063143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure TensorFlow to use GPU and set memory growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ],
   "id": "57b6de1b6eb5b545",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load IndoBERT Tokenizer and Model",
   "id": "89ec32539ff19409"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T17:54:23.318949Z",
     "start_time": "2024-08-10T17:54:21.305585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load IndoBERT tokenizer and model (TensorFlow version)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "bert_model = TFBertModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "bert_model.config.gradient_checkpointing = True\n"
   ],
   "id": "754200727f07c69c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at indobenchmark/indobert-base-p1 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at indobenchmark/indobert-base-p1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Generator for Reading Text Files",
   "id": "61be31e1ee5bb499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T17:54:38.226615Z",
     "start_time": "2024-08-10T17:54:38.219607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generator to read text files and clean text\n",
    "def read_text_files_generator(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                content = file.read().strip().lower()\n",
    "                if content:\n",
    "                    yield clean_text(content)\n",
    "\n",
    "def clean_text(text):\n",
    "    unwanted_chars = ['*', '#', '_', ')', '(', '!', '?', '.', ',', '-']\n",
    "    for char in unwanted_chars:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n"
   ],
   "id": "1a76e22594b50868",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process and Tokenize Text in Batches Using Generator",
   "id": "bbf9d72465de828b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T18:02:08.492001Z",
     "start_time": "2024-08-10T18:01:42.924244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Function to tokenize and save batches\n",
    "def tokenize_and_save_batch(texts, batch_index, tokenizer, save_dir):\n",
    "    batch_dataset = Dataset.from_dict({\"text\": texts})\n",
    "    tokenized_batch = batch_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "    tokenized_batch.save_to_disk(f'{save_dir}/tokenized_dataset_batch_{batch_index}')\n",
    "\n",
    "# Process texts in batches and save tokenized datasets\n",
    "def process_in_batches(folder_path, batch_size, tokenizer, save_dir):\n",
    "    batch_texts = []\n",
    "    batch_index = 0\n",
    "    for text in read_text_files_generator(folder_path):\n",
    "        batch_texts.append(text)\n",
    "        if len(batch_texts) >= batch_size:\n",
    "            tokenize_and_save_batch(batch_texts, batch_index, tokenizer, save_dir)\n",
    "            batch_texts = []\n",
    "            batch_index += 1\n",
    "    if batch_texts:\n",
    "        tokenize_and_save_batch(batch_texts, batch_index, tokenizer, save_dir)\n",
    "\n",
    "# Example usage:\n",
    "process_in_batches('../Dataset/nlp_dataset', batch_size=100, tokenizer=tokenizer, save_dir='../saved_model/nlp_saved/nlp_02/new_tokenized')\n"
   ],
   "id": "5c81d714d4579ea4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3de8a342ca7d4bc1a01821a2bd10cfb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af3aa8a105bb4ad4a00f0e24aee250ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "526d37de958b4b49a0a7af5c5a77f2cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceab7e040aab48e8aa564b9241bdf00b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8148d4bd9e934b689885a1b9aebe1b8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a9022aa780e40349a7b6b3bf3ab8e9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c95a29490cb74f3b8671fc953f0724c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e66b695f37549f09ecd36e9ac3abf84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0902b53c338a4ed1b4f692e629a444dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30e03b37752d44e0a3b6235ad56cafc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91c0a311a5cd41a9bba351a1ff61114f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "794121e010fb436199bd1df1ad874e10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eae0ef2272f848d992806a0b2c26aa88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35fab979fe514a3f8ddadc232b945e05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0486df1e6c3744c09db88225bcfe0778"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18f3cfe951b04cb0b744ac613e97ec27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03569b125e954dbf9734d6f0800e51f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61c0b678bb5540ffb88b9a6cb1a7ce8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31f663dda90a428cae5d2b4307bfed79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "139caf704b2c4f45b7a04b7526e5a8b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19f6670da0ea416da26a9605a1f0235b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "915cc2980c234fa280e6ad1353902cba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d27619c61b3548ce9cf211826f11fc5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d36b3d05a3a472dbfd17a55a4b68f12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c987350d8e364737a31299b9c77d21ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db57f90d2a1e43e2959707fd02e0a170"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/92 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34438e18cd3649f9bb63b36743dae027"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/92 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b1370badd344ef0b1b51f3ffdb922bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and Prepare Dataset with Prefetching",
   "id": "57ab42ca358d3eb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T18:10:32.594159Z",
     "start_time": "2024-08-10T18:10:32.578512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset with prefetching for efficient training\n",
    "def load_and_prepare_dataset_with_prefetch(batch_index, save_dir):\n",
    "    batch_dataset = load_from_disk(f'{save_dir}/tokenized_dataset_batch_{batch_index}')\n",
    "    dataset = batch_dataset.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        label_cols=[\"input_ids\"],\n",
    "        shuffle=True,\n",
    "        batch_size=1,\n",
    "        collate_fn=None,\n",
    "    )\n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ],
   "id": "7b21d19b6094239d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define and Compile BertAutoencoder Model",
   "id": "e154b925c820d075"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T18:10:33.397789Z",
     "start_time": "2024-08-10T18:10:33.376956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the BertAutoencoder model\n",
    "class BertAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, bert_model):\n",
    "        super(BertAutoencoder, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dense = tf.keras.layers.Dense(bert_model.config.vocab_size, activation='softmax', dtype='float32')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.bert(**inputs)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        reconstructed = self.dense(sequence_output)\n",
    "        return reconstructed\n",
    "\n",
    "# Instantiate the model\n",
    "autoencoder_model = BertAutoencoder(bert_model)\n",
    "\n",
    "# Optimizer using LossScaleOptimizer with dynamic loss scale\n",
    "base_optimizer = Adam(learning_rate=2e-5)\n",
    "optimizer = LossScaleOptimizer(base_optimizer)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ],
   "id": "489f3628a075920",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Model in Batches with Prefetching",
   "id": "f78717ef87b4b00d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T18:10:59.610061Z",
     "start_time": "2024-08-10T18:10:34.397026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to train the model on prefetch-enabled datasets in batches\n",
    "def train_model_with_prefetching(model, num_batches, save_dir):\n",
    "    for i in range(num_batches):\n",
    "        print(f\"Training on batch {i+1}/{num_batches}\")\n",
    "        train_dataset = load_and_prepare_dataset_with_prefetch(i, save_dir)\n",
    "        model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# Example usage:\n",
    "train_model_with_prefetching(autoencoder_model, 500, '../saved_model/nlp_saved/nlp_02/new_tokenized')\n"
   ],
   "id": "79f2927b567baa02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/500\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2295026956.py\", line 9, in <module>\n      train_model_with_prefetching(autoencoder_model, 500, '../saved_model/nlp_saved/nlp_02/new_tokenized')\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2295026956.py\", line 6, in train_model_with_prefetching\n      model.fit(train_dataset, epochs=3)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2740090188.py\", line 9, in call\n      outputs = self.bert(**inputs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1208, in run_call_with_unpacked_inputs\n      \"\"\"\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1235, in call\n      outputs = self.bert(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1208, in run_call_with_unpacked_inputs\n      \"\"\"\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 995, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 629, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 635, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 528, in call\n      self_attention_outputs = self.attention(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 412, in call\n      self_outputs = self.self_attention(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 316, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul'\nOOM when allocating tensor with shape[1,12,512,512] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_53369]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m         model\u001B[38;5;241m.\u001B[39mfit(train_dataset, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Example usage:\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtrain_model_with_prefetching\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../saved_model/nlp_saved/nlp_02/new_tokenized\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[17], line 6\u001B[0m, in \u001B[0;36mtrain_model_with_prefetching\u001B[1;34m(model, num_batches, save_dir)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining on batch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_batches\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m load_and_prepare_dataset_with_prefetch(i, save_dir)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\windows_events.py\", line 321, in run_forever\n      super().run_forever()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2295026956.py\", line 9, in <module>\n      train_model_with_prefetching(autoencoder_model, 500, '../saved_model/nlp_saved/nlp_02/new_tokenized')\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2295026956.py\", line 6, in train_model_with_prefetching\n      model.fit(train_dataset, epochs=3)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_25068\\2740090188.py\", line 9, in call\n      outputs = self.bert(**inputs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1208, in run_call_with_unpacked_inputs\n      \"\"\"\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1235, in call\n      outputs = self.bert(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1208, in run_call_with_unpacked_inputs\n      \"\"\"\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 995, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 629, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 635, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 528, in call\n      self_attention_outputs = self.attention(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 412, in call\n      self_outputs = self.self_attention(\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\gabri\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 316, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul'\nOOM when allocating tensor with shape[1,12,512,512] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node bert_autoencoder_2/tf_bert_model/bert/encoder/layer_._2/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_53369]"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5594e77403720e54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
